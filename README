the activation base function we are working with is 
-function :  x + (L / (Q * (x + I) ** P + Z)) - (L / (Q * (x - I) ** P + Z))
-link to desmos graph :https://www.desmos.com/calculator/0hiyjyun2f (move points to play with the parameters)

each file as a section of configuration part, example ,if we want to check certain parameters ,
how many times we want to run relu on a certain amount of epchs, if we want to get the best score of relu,etc..
after configuration simply run all to see the results.



------------------------------------------------
file : global_parameters_finder_cifar10.ipyn
________________________________________________
this file run on cifar10 image's, first section is the part needed to be configure by the user want's and it looks for the best activation function for resnet 9.



------------------------------------------------
file : inequalityFinder.ipynb
________________________________________________
this file is an exmaple to transform our function to a inequality function, simply add the parameters to the sec section and run




------------------------------------------------
file : global_parameters_resnet9_cifar100.ipynb
________________________________________________
this file run on cifar100 image's, the third section is the part needed to be configure by the user want's,it can be configuried to find the best activation function ,
test the activation function by comparing to relu and with an additonal option , to transform the certain function we found to an inequality funcation,after configuration,
simply run all. this note notebook run on resnet9 neural network, and the focus is to find an activation function that give better results then relu.




------------------------------------------------
file : layers_unique_parameters_cifar100.ipynb
________________________________________________
same as before , but this time with the option to look specifc for each layer what is the best activation function, 
and not a global one for all the layers, configuration at the sec section, run on cifar 100 data, 
use resnet9 neural network with the option to set a diffrent activation funcation parameters for each of the 8 layers 
